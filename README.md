### About
Implement change data capture on operational source system and process the data to get slowly changing dimension tables.

<br>

### Pipeline
![alt text](https://github.com/MinThuraZaw/PySpark-ETL-with-AWS-DMS-and-Databricks/blob/main/images/dms_pipeline.jpg)

<br>

### Requirements
1) Operational Database
2) AWS DMS
3) AWS S3
4) Databricks

**Languages**
* PySpark
* Spark SQL

<br>

### Development Steps

